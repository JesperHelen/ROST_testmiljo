{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecf2dbb4-2647-4b18-933b-8d0dc2f4592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "import geopandas as gpd\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "941ff093-e321-43c6-a76b-98ed5d3ef13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Message</th>\n",
       "      <th>Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-14 10.54.56</td>\n",
       "      <td>13,842585</td>\n",
       "      <td>100,571712</td>\n",
       "      <td>Risky intersection with fast moped traffic</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-14 10.55.00</td>\n",
       "      <td>13,842632</td>\n",
       "      <td>100,571648</td>\n",
       "      <td>Intersection unsafe due to reckless driving</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-14 10.55.14</td>\n",
       "      <td>13,842752</td>\n",
       "      <td>100,571884</td>\n",
       "      <td>High-speed cars make this intersection hazardous</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-14 10.55.32</td>\n",
       "      <td>13,8427</td>\n",
       "      <td>100,571696</td>\n",
       "      <td>Vehicles racing through the intersection, used...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-14 10.56.33</td>\n",
       "      <td>13,84258</td>\n",
       "      <td>100,571664</td>\n",
       "      <td>Intersection known for accidents and speeding</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp   Latitude   Longitude  \\\n",
       "0  2025-02-14 10.54.56  13,842585  100,571712   \n",
       "1  2025-02-14 10.55.00  13,842632  100,571648   \n",
       "2  2025-02-14 10.55.14  13,842752  100,571884   \n",
       "3  2025-02-14 10.55.32    13,8427  100,571696   \n",
       "4  2025-02-14 10.56.33   13,84258  100,571664   \n",
       "\n",
       "                                             Message   Opinion  \n",
       "0         Risky intersection with fast moped traffic  Negative  \n",
       "1        Intersection unsafe due to reckless driving  Negative  \n",
       "2   High-speed cars make this intersection hazardous  Negative  \n",
       "3  Vehicles racing through the intersection, used...  Negative  \n",
       "4      Intersection known for accidents and speeding  Negative  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/export?format=csv&gid=0\"\n",
    "\n",
    "# https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/edit?gid=0#gid=0\n",
    "# https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/export?format=csv&gid=0\n",
    "\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ab3103f-6bfd-40f0-aa79-1a7d8c8e9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 40, but your input_length is only 6. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n",
      "D:\\Anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Your max_length is set to 40, but your input_length is only 6. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n",
      "Your max_length is set to 40, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 40, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 40, but your input_length is only 15. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 40, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 40, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "Your max_length is set to 40, but your input_length is only 11. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=5)\n",
      "Your max_length is set to 40, but your input_length is only 11. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=5)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] Det går inte att komma åt filen eftersom den\r\nanvänds av en annan process: 'clusters_by_opinion_improved.geojson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusters_by_opinion_improved.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusters_by_opinion_improved.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m clusters_gdf_opinion\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusters_by_opinion_improved.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m, driver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoJSON\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Print a preview\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] Det går inte att komma åt filen eftersom den\r\nanvänds av en annan process: 'clusters_by_opinion_improved.geojson'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiPoint\n",
    "import hdbscan\n",
    "from transformers import pipeline\n",
    "\n",
    "##############################################################################\n",
    "# 1) Load / Prepare Your DataFrame (df) with columns:\n",
    "#    ['Timestamp', 'Latitude', 'Longitude', 'Message', 'Opinion']\n",
    "##############################################################################\n",
    "\n",
    "# Example: If you've already got df, skip these lines:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Map Opinion to numerical Value\n",
    "mapping = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "df['Value'] = df['Opinion'].map(mapping)\n",
    "\n",
    "# Convert coordinates from string with commas to float\n",
    "def convert_coord(coord):\n",
    "    if isinstance(coord, str):\n",
    "        return float(coord.replace(',', '.'))\n",
    "    return float(coord)\n",
    "\n",
    "df['Latitude'] = df['Latitude'].apply(convert_coord)\n",
    "df['Longitude'] = df['Longitude'].apply(convert_coord)\n",
    "\n",
    "##############################################################################\n",
    "# 2) Summarization Pipeline: T5 with chunk-based approach\n",
    "##############################################################################\n",
    "\n",
    "# Initialize summarizer with a T5 model\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"google/flan-t5-large\",  # Try other T5 or Pegasus models if you prefer\n",
    "    do_sample=False,               # More deterministic output\n",
    "    truncation=True                # Truncate if input is too long\n",
    ")\n",
    "\n",
    "def chunk_summarize(messages, \n",
    "                    chunk_size=5, \n",
    "                    max_length=40, \n",
    "                    min_length=5):\n",
    "    \"\"\"\n",
    "    1. Split 'messages' into smaller chunks.\n",
    "    2. Summarize each chunk individually.\n",
    "    3. Summarize the concatenation of those chunk summaries.\n",
    "    \"\"\"\n",
    "    # Summaries of each chunk\n",
    "    chunk_summaries = []\n",
    "    \n",
    "    for i in range(0, len(messages), chunk_size):\n",
    "        chunk = messages[i:i+chunk_size]\n",
    "        text = \" \".join(chunk)\n",
    "        \n",
    "        # Summarize the chunk with stricter parameters\n",
    "        partial_summary = summarizer(\n",
    "            text, \n",
    "            max_length=max_length, \n",
    "            min_length=min_length,\n",
    "            no_repeat_ngram_size=3,   # reduce repeated phrases\n",
    "            early_stopping=True\n",
    "        )\n",
    "        chunk_summaries.append(partial_summary[0]['summary_text'])\n",
    "    \n",
    "    # Now summarize the concatenated chunk_summaries\n",
    "    combined_text = \" \".join(chunk_summaries)\n",
    "    final_summary = summarizer(\n",
    "        combined_text,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        no_repeat_ngram_size=3,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    return final_summary[0]['summary_text']\n",
    "\n",
    "##############################################################################\n",
    "# 3) Group by Opinion, then cluster each group spatially with HDBSCAN\n",
    "##############################################################################\n",
    "\n",
    "clusters_list = []\n",
    "\n",
    "for opinion in df['Opinion'].unique():\n",
    "    sub_df = df[df['Opinion'] == opinion].copy()\n",
    "    coords = sub_df[['Longitude', 'Latitude']].values\n",
    "    \n",
    "    # Skip if too few points\n",
    "    if len(coords) < 3:\n",
    "        continue\n",
    "    \n",
    "    # HDBSCAN clustering\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=3)\n",
    "    sub_df['cluster'] = clusterer.fit_predict(coords)\n",
    "    \n",
    "    for cl in sorted(sub_df['cluster'].unique()):\n",
    "        if cl == -1:  # ignore noise\n",
    "            continue\n",
    "        cluster_data = sub_df[sub_df['cluster'] == cl]\n",
    "        \n",
    "        # Build a convex hull from the points\n",
    "        points = [\n",
    "            Point(lon, lat) \n",
    "            for lon, lat in zip(cluster_data['Longitude'], cluster_data['Latitude'])\n",
    "        ]\n",
    "        if not points:\n",
    "            continue\n",
    "        \n",
    "        hull = MultiPoint(points).convex_hull\n",
    "        agg_value = cluster_data['Value'].sum()\n",
    "        \n",
    "        # Summarize all messages in this cluster (chunk-based)\n",
    "        messages = cluster_data['Message'].tolist()\n",
    "        summary_text = chunk_summarize(messages, chunk_size=5, max_length=40, min_length=5)\n",
    "        \n",
    "        clusters_list.append({\n",
    "            'Opinion': opinion,\n",
    "            'cluster': f\"{opinion}_{cl}\",\n",
    "            'AggregateValue': agg_value,\n",
    "            'Summary': summary_text,\n",
    "            'geometry': hull\n",
    "        })\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "clusters_gdf_opinion = gpd.GeoDataFrame(clusters_list, crs=\"EPSG:4326\")\n",
    "\n",
    "##############################################################################\n",
    "# 4) Save the Result to GeoJSON for QGIS\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "clusters_gdf_opinion.to_file(\"clusters_by_opinion_improved2.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# Print a preview\n",
    "print(\"Clusters with Summaries:\")\n",
    "print(clusters_gdf_opinion[['Opinion','cluster','AggregateValue','Summary']])\n",
    "print(\"\\nSaved to 'clusters_by_opinion_improved.geojson'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
