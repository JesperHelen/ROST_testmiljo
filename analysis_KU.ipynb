{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf2dbb4-2647-4b18-933b-8d0dc2f4592c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: No module named 'numpy._utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\pandas\\__init__.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: No module named 'numpy._utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d181c27d-00dc-4cd6-9393-786bb18871d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/b9/c6/cd4298729826af9979c5f9ab02fcaa344b82621e7c49322cd2d210483d3f/numpy-2.2.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-2.2.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (D:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (D:\\Anaconda3\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Ã…tkomst nekad: 'D:\\\\Anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\linalg\\\\_umath_linalg.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ff093-e321-43c6-a76b-98ed5d3ef13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/export?format=csv&gid=0\"\n",
    "\n",
    "# https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/edit?gid=0#gid=0\n",
    "# https://docs.google.com/spreadsheets/d/14ztIrZ3BsqPgJlEbw84kYlZykzfluZFynpK9ENTJ5UA/export?format=csv&gid=0\n",
    "\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3103f-6bfd-40f0-aa79-1a7d8c8e9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 2. Convert Coordinates to Floats\n",
    "# -------------------------------\n",
    "# Replace commas with periods and cast to float.\n",
    "df['Latitude'] = df['Latitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['Longitude'] = df['Longitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Create a GeoDataFrame & Project\n",
    "# -------------------------------\n",
    "# Create GeoDataFrame (x=Longitude, y=Latitude)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "# Reproject to a metric CRS so that distances (e.g., 100 meters) are meaningful.\n",
    "# Here, using UTM zone 47N (EPSG:32647); adjust if needed.\n",
    "gdf = gdf.to_crs(epsg=32647)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Spatial Clustering (DBSCAN)\n",
    "# -------------------------------\n",
    "# Extract projected coordinates (in meters)\n",
    "coords = np.array([[geom.x, geom.y] for geom in gdf.geometry])\n",
    "# Cluster points that are within 100 meters (min_samples=2)\n",
    "spatial_db = DBSCAN(eps=100, min_samples=2)\n",
    "gdf['spatial_cluster'] = spatial_db.fit_predict(coords)\n",
    "\n",
    "print(\"Spatial clustering results:\")\n",
    "print(gdf[['Timestamp', 'spatial_cluster']])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Semantic Text Clustering Using SentenceTransformer\n",
    "# -------------------------------\n",
    "# Load the pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def text_clustering_embeddings(texts, eps=0.4, min_samples=1):\n",
    "    \"\"\"\n",
    "    Cluster a list of text strings using SentenceTransformer embeddings and DBSCAN.\n",
    "    \n",
    "    eps: Maximum cosine distance between samples to be considered in the same cluster.\n",
    "    min_samples: Minimum number of samples in a cluster.\n",
    "    \"\"\"\n",
    "    if len(texts) == 0:\n",
    "        return []\n",
    "    # Generate embeddings for the texts\n",
    "    embeddings = model.encode(texts)\n",
    "    # Cluster using DBSCAN with cosine metric (distance = 1 - cosine similarity)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')\n",
    "    labels = clustering.fit_predict(embeddings)\n",
    "    return labels\n",
    "\n",
    "# Combine spatial clusters, Opinion grouping, and semantic text clusters.\n",
    "final_cluster_ids = {}\n",
    "\n",
    "for spatial_label in gdf['spatial_cluster'].unique():\n",
    "    if spatial_label == -1:\n",
    "        # For noise points, assign a unique ID.\n",
    "        for idx in gdf[gdf['spatial_cluster'] == -1].index:\n",
    "            final_cluster_ids[idx] = f\"noise_{idx}\"\n",
    "    else:\n",
    "        sub_gdf = gdf[gdf['spatial_cluster'] == spatial_label]\n",
    "        # Further group by Opinion so that only points with the same opinion are clustered together.\n",
    "        for opinion, group in sub_gdf.groupby('Opinion'):\n",
    "            texts = group['Message'].tolist()\n",
    "            # Use semantic clustering on the messages.\n",
    "            text_labels = text_clustering_embeddings(texts, eps=0.4, min_samples=1)\n",
    "            for idx, t_label in zip(group.index, text_labels):\n",
    "                final_cluster_ids[idx] = f\"sp{spatial_label}_{opinion}_t{t_label}\"\n",
    "\n",
    "# Map final cluster IDs back to the GeoDataFrame.\n",
    "gdf['final_cluster'] = gdf.index.map(final_cluster_ids)\n",
    "\n",
    "print(\"\\nFinal clusters (spatial + opinion + semantic):\")\n",
    "print(gdf[['Timestamp', 'final_cluster', 'Message']])\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Generate Cluster Polygons & Summaries\n",
    "# -------------------------------\n",
    "polygons = {}\n",
    "summaries = {}\n",
    "\n",
    "# For each final cluster, compute the convex hull polygon and a summary.\n",
    "for cluster_id in gdf['final_cluster'].unique():\n",
    "    cluster_points = gdf[gdf['final_cluster'] == cluster_id]\n",
    "    if len(cluster_points) > 0:\n",
    "        # Create a convex hull for the cluster points.\n",
    "        polygon = MultiPoint(list(cluster_points.geometry)).convex_hull\n",
    "        polygons[cluster_id] = polygon\n",
    "        # Simple summary: join all messages in the cluster (customize as needed)\n",
    "        summaries[cluster_id] = \" | \".join(cluster_points['Message'].tolist())\n",
    "\n",
    "clusters_gdf = gpd.GeoDataFrame({\n",
    "    'final_cluster': list(polygons.keys()),\n",
    "    'summary': [summaries[cid] for cid in polygons.keys()],\n",
    "    'geometry': list(polygons.values())\n",
    "}, crs=gdf.crs)\n",
    "\n",
    "print(\"\\nCluster polygons and summaries:\")\n",
    "print(clusters_gdf)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Plot the Results\n",
    "# -------------------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "clusters_gdf.plot(ax=ax, alpha=0.5, edgecolor='k', column='final_cluster', legend=True)\n",
    "gdf.plot(ax=ax, color='red', markersize=5)\n",
    "plt.title(\"Final Clusters with Polygons\")\n",
    "plt.xlabel(\"Easting (m)\")\n",
    "plt.ylabel(\"Northing (m)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
